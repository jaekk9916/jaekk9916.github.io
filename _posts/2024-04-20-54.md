---
title: Object Detection
date: 2024-04-20 20:32:19 -0500
categories: [AI, Deep Learning]
tags: [Deep Learning]
---
## Object Localization

### Image Classification

- **Purpose:** Identifies a single object in an image and assigns it a specific label (e.g., "car").

### Object Localization

- **Purpose:** Recognizes and determines the precise location and size of an object within an image by drawing a bounding box around it.
- **Relation to Object Detection:** It is a fundamental component of object detection, which deals with detecting multiple objects.

### Classification with Localization

- **Outputs:** In addition to the objectâ€™s class, the neural network outputs four parameters (bx, by, bh, bw) that define the bounding box of the detected object. These parameters are part of the output vector y.
- **Bounding Box Coordinates:** The image is conceptually mapped such that the upper-left corner is (0,0) and the lower-right corner is (1,1).
- **Output Vector Components:**
    - **pc:** Indicates the presence (1) or absence (0) of a classifiable object (not background).
    - **bx, by, bh, bw:** Specify the bounding box dimensions and position.
    - **c1, c2, c3:** Class indicators, which determine whether the object is a pedestrian, car, or motorcycle. When an object is present (pc = 1), one of these indicators will also be 1. If no object is detected, these are irrelevant.
- **Loss Function:** Training uses a sum of squared errors to minimize the differences between predicted outputs and actual labels for all components of y. Focus is on all components when an object is detected, and solely on pc when no object is present.

### Object Detection

- **Purpose:** Detects and localizes multiple objects within a single image, each potentially belonging to different categories.
- **Complexity:** Handles more complex scenes with multiple dynamic and static objects, crucial for applications like autonomous driving.

![Pasted image 20240420193702](https://github.com/jaekk9916/jaekk9916.github.io/assets/96701717/19da328b-4d5a-417a-9f49-b81295629e24)
<br>
## Landmark Detection
### Landmark Detection

- **Capability**: Now able to output X and Y coordinates of critical points or landmarks within images.
- **Utility**: Extremely useful in applications like face recognition, where it's crucial to precisely identify specific details such as the corners of eyes.

### Multiple Landmark Outputs

- **Functionality**: Networks can be tailored to output coordinates for multiple landmarks, accommodating complex requirements like identifying all corners of the eyes or other detailed facial features, with capability extending up to 64 points on a face.

### Network Configuration

- **Setup**: Configured to have 129 output units; one unit to detect the presence of a face and 128 units to manage the coordinates of 64 landmarks.

### Applications in Emotion Recognition and Augmented Reality

- **Foundational Technologies**: These capabilities underpin advanced technologies such as emotion recognition and augmented reality filters, which dynamically apply effects based on detected facial landmarks.
- **Training Requirements**: Effective training demands a well-labeled dataset with consistent annotations across all images to ensure accurate landmark detection.

### Extension to Pose Detection

- **Application Extension**: Extends to pose detection, where the network identifies key body positions, useful in various fields from health monitoring to interactive gaming.

### Consistency Requirement

- **Importance**: It's essential that the identity of each landmark remains consistent across different images to ensure the network's reliability and accuracy.
<br><br><br>
reference:<br>
<a href="https://www.coursera.org/learn/convolutional-neural-networks">Coursera - Convolutional Neural Networks</a>
